{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a9d5ae-982e-4638-8fa9-6b842cf95a4f",
   "metadata": {},
   "source": [
    "edited: 2023-02-21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c79d3a-ba9b-4907-b9b7-52c81c017a1e",
   "metadata": {},
   "source": [
    "# User Defined Functions (UDF)\n",
    "\n",
    "What if the transformation we need is not supplied by Spark?\n",
    "\n",
    "We can add our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacaa6a-64fe-4b3d-b266-80ad9018d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef1c4f-b2bd-4cd8-8d5d-c3e159821c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(col):\n",
    "    if col % 2:\n",
    "        return col/2\n",
    "    return col * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b2c8a-39a2-4fe6-8c24-c896b4fedecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_func = f.udf(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30175842-dc01-41cd-b824-ce6a5ef879cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(500)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea8132d-eaf0-4245-bb9c-0bf52cb68d94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a new column, computed from the \"id\" column\n",
    "df2 = df.withColumn('computed', sp_func('id'))\n",
    "df2.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44aa133-9a34-45e9-8702-6cf612d83267",
   "metadata": {},
   "source": [
    "## what about performance?\n",
    "\n",
    "Summary: If you can use use regular Spark functions, use them. Use UDF only if no choice.\n",
    "\n",
    "See :\n",
    "\n",
    "https://medium.com/quantumblack/spark-udf-deep-insights-in-performance-f0a95a4d8c62#:~:text=In%20these%20circumstances%2C%20PySpark%20UDF,two%20types%20of%20PySpark%20UDFs.\n",
    "\n",
    "https://stackoverflow.com/questions/38296609/spark-functions-vs-udf-performance\n",
    "\n",
    "https://www.databricks.com/session_eu20/optimizing-apache-spark-udfs\n",
    "\n",
    "\n",
    "\n",
    "When calling a UDF (either scala or python), the data has to be serialized (from the internal representation in the JVM), deserialized to pass to the function and then back.\n",
    "Even strings might be serialized due to change in representation (utf-8 / utf-16)\n",
    "\n",
    "With Python, there is another stage: the data is copied from the JVM process to the python process (in the same executor)\n",
    "[ NOTE: possibly even worse: If only the driver has python process, then all the data will be sent from the executors in the workers to the driver node, and then back ]\n",
    "\n",
    "Some python UDF functions are called on a vector (instead of a single row), so the performance is much better. In any case, it will be worse (by as much as 10x) then the scala UDF.\n",
    "\n",
    "For details, see https://www.databricks.com/blog/2022/11/30/memory-profiling-pyspark.html : *Memory Profiling in PySpark*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1370b-4bd8-456c-b0f2-b0278d4a4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(f.expr('id*2')).show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd72314-75b3-4120-ac59-ac048b11006b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
