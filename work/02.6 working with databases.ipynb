{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1c5011-8e4a-46e8-a52e-80d5178ae39b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with a Database\n",
    "\n",
    "For this lesson, you first have to prepare a database.\n",
    "\n",
    "Follow the instructions in ''\n",
    "## Install the DB driver\n",
    "\n",
    "Before using a database, we need to install a driver for the specific database we use.\n",
    "\n",
    "In our example, we use postgres, so go to https://jdbc.postgresql.org/download/ and download the latest driver for latest Java (\"postgresql-42.5.4.jar\" for me)\n",
    "\n",
    "### Copy the driver to the Spark node (a Docker container in our case)\n",
    "```\n",
    "$ docker cp /home/cnoam/Downloads/postgresql-42.5.4.jar spark-lab:/usr/local/spark-3.2.0-bin-hadoop3.2/jars\n",
    "Successfully copied 1.052MB to spark-lab:/usr/local/spark-3.2.0-bin-hadoop3.2/jars\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Reading/Writing from RDBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd154773-6f60-48ec-be83-af50b649fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars\", \"/usr/local/spark-3.2.0-bin-hadoop3.2/jars/postgresql-42.5.4.jar\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Which Database server are we connecting to?\n",
    "# if running in local Docker, we put both Spark and Postgres servers in the same Docker network ('spark_backend')\n",
    "# Actually, if the postgres server is used ONLY by the Spark server, there is no need to expose its ports\n",
    "hostname=\"db\"  # the service name in docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a0dec-5637-45af-ae9d-1133e7cf35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = f\"jdbc:postgresql://{hostname}/\"\n",
    "database_name = \"bids_db\"\n",
    "url = server_name + database_name\n",
    "table_name = \"players\"\n",
    "username = \"postgres\"  # your_dbuser_name_here\n",
    "password = \"postgres\"\n",
    "\n",
    "# We don't even need to add 'option(\"driver\", \"org.postgresql.Driver\")'\n",
    "\n",
    "jdbcDF = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"dbtable\", table_name)\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", password).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8c292-042b-4063-8ee3-980f4ed49f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1cd60-3660-45db-bc12-002f87eb6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a few rows\n",
    "from pyspark.sql.types import StructType,StructField, StringType,IntegerType\n",
    "playerSchema = StructType([StructField('name',StringType(),False), \n",
    "                          StructField('Age',IntegerType(),False),\n",
    "                          StructField('occupation',StringType(),False)\n",
    "                          ])\n",
    "newcomers = [('נעם', 59, 'Witcher'), ('Helga', 140, 'hag')]\n",
    "newPlayers=spark.createDataFrame(data=newcomers, schema= playerSchema)\n",
    "newPlayers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682916af-71ab-492b-a61d-020d4553d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    newPlayers.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"url\", url) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", username) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .save()\n",
    "except ValueError as error:\n",
    "    print(\"Connector write failed\", error)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716de700-cd81-439e-9bcb-5c7118b0a42f",
   "metadata": {},
   "source": [
    "And you can check in the dbclient:\n",
    "```\n",
    "bids_db=# select * from players;\n",
    "  name   | age | occupation  \n",
    "---------+-----+-------------\n",
    " Alice   |  25 |  Rocker\n",
    " Bob     |  30 |  Assasin\n",
    " Charlie |  50 |  politician\n",
    " David   |  10 |  racer\n",
    " נעם     |  59 | Witcher\n",
    " Helga   | 140 | hag\n",
    "(6 rows)\n",
    "```\n",
    "PS: the Hebrew text is in the wrong place. A bug in the terminal..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d8d2d-77b3-42f0-9560-99198b96d898",
   "metadata": {},
   "source": [
    "# Reading / Writing to other databses\n",
    "\n",
    "In the lesson on Streaming we read from Kafka source.\n",
    "Simlarly, we can read from other sources such as mongodb using a *connector* supplied by the database vendor\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec58d92-e413-4b8a-9589-5abfee323018",
   "metadata": {},
   "source": [
    "df = spark.read.format(\"mongo\").option(\"uri\",\n",
    "\"mongodb://127.0.0.1/people.contacts\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eec6dd-b78d-4d00-960d-6981f9cdf218",
   "metadata": {},
   "source": [
    "<br>This will write to a default container in the database you connected to before"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebe21a90-16a1-4fc3-991a-aabdb9772e03",
   "metadata": {},
   "source": [
    "people = spark.createDataFrame([(\"Bilbo Baggins\",  50), (\"Gandalf\", 1000)], [\"name\", \"age\"])\n",
    "people.write.format(\"mongo\").mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
