{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeStations = spark.read.option(\"header\",\"true\")\\\n",
    "  .csv(\"/data/bike-data/201508_station_data.csv\")\n",
    "tripData = spark.read.option(\"header\",\"true\")\\\n",
    "  .csv(\"/data/bike-data/201508_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationVertices = bikeStations.withColumnRenamed(\"name\", \"id\").distinct()\n",
    "tripEdges = tripData\\\n",
    "  .withColumnRenamed(\"Start Station\", \"src\")\\\n",
    "  .withColumnRenamed(\"End Station\", \"dst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import GraphFrame\n",
    "stationGraph = GraphFrame(stationVertices, tripEdges)\n",
    "stationGraph.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Total Number of Stations: \" + str(stationGraph.vertices.count())\n",
    "print \"Total Number of Trips in Graph: \" + str(stationGraph.edges.count())\n",
    "print \"Total Number of Trips in Original Data: \" + str(tripData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "stationGraph.edges.groupBy(\"src\", \"dst\").count().orderBy(desc(\"count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationGraph.edges\\\n",
    "  .where(\"src = 'Townsend at 7th' OR dst = 'Townsend at 7th'\")\\\n",
    "  .groupBy(\"src\", \"dst\").count()\\\n",
    "  .orderBy(desc(\"count\"))\\\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "townAnd7thEdges = stationGraph.edges\\\n",
    "  .where(\"src = 'Townsend at 7th' OR dst = 'Townsend at 7th'\")\n",
    "subgraph = GraphFrame(stationGraph.vertices, townAnd7thEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = stationGraph.find(\"(a)-[ab]->(b); (b)-[bc]->(c); (c)-[ca]->(a)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "motifs.selectExpr(\"*\",\n",
    "    \"to_timestamp(ab.`Start Date`, 'MM/dd/yyyy HH:mm') as abStart\",\n",
    "    \"to_timestamp(bc.`Start Date`, 'MM/dd/yyyy HH:mm') as bcStart\",\n",
    "    \"to_timestamp(ca.`Start Date`, 'MM/dd/yyyy HH:mm') as caStart\")\\\n",
    "  .where(\"ca.`Bike #` = bc.`Bike #`\").where(\"ab.`Bike #` = bc.`Bike #`\")\\\n",
    "  .where(\"a.id != b.id\").where(\"b.id != c.id\")\\\n",
    "  .where(\"abStart < bcStart\").where(\"bcStart < caStart\")\\\n",
    "  .orderBy(expr(\"cast(caStart as long) - cast(abStart as long)\"))\\\n",
    "  .selectExpr(\"a.id\", \"b.id\", \"c.id\", \"ab.`Start Date`\", \"ca.`End Date`\")\\\n",
    "  .limit(1).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "ranks = stationGraph.pageRank(resetProbability=0.15, maxIter=10)\n",
    "ranks.vertices.orderBy(desc(\"pagerank\")).select(\"id\", \"pagerank\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inDeg = stationGraph.inDegrees\n",
    "inDeg.orderBy(desc(\"inDegree\")).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDeg = stationGraph.outDegrees\n",
    "outDeg.orderBy(desc(\"outDegree\")).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degreeRatio = inDeg.join(outDeg, \"id\")\\\n",
    "  .selectExpr(\"id\", \"double(inDegree)/double(outDegree) as degreeRatio\")\n",
    "degreeRatio.orderBy(desc(\"degreeRatio\")).show(10, False)\n",
    "degreeRatio.orderBy(\"degreeRatio\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationGraph.bfs(fromExpr=\"id = 'Townsend at 7th'\",\n",
    "  toExpr=\"id = 'Spear at Folsom'\", maxPathLength=2).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minGraph = GraphFrame(stationVertices, tripEdges.sample(False, 0.1))\n",
    "cc = minGraph.connectedComponents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.where(\"component != 0\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc = minGraph.stronglyConnectedComponents(maxIter=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
