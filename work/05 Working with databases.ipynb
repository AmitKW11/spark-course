{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1c5011-8e4a-46e8-a52e-80d5178ae39b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with a Database\n",
    "\n",
    "For this lesson, you first have to prepare a database.\n",
    "\n",
    "Follow the instructions in *./postgres_in_docker/README.md*\n",
    "\n",
    "### Verify the DB is up\n",
    "run `$ docker ps | grep postg`\n",
    "\n",
    "You should see output similar to:\n",
    "```\n",
    "ca09314c8dad   postgres   \"docker-entrypoint.s…\"   3 minutes ago    Up 3 minutes    5432/tcp    psqlserver\n",
    "```\n",
    "\n",
    "## Install the DB driver\n",
    "\n",
    "Before using a database, we need to install a *driver* for the specific database we use.\n",
    "\n",
    "In our example, we use postgres.\n",
    "\n",
    "The driver from https://jdbc.postgresql.org/download/ is already downloaded into the ./jars folder\n",
    "\n",
    "### Copy the driver to the Spark node (a Docker container in our case)\n",
    "```\n",
    "$ docker cp jars/postgresql-42.5.4.jar spark-lab:/usr/local/spark/jars\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Reading/Writing from RDBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd154773-6f60-48ec-be83-af50b649fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars\", \"/usr/local/spark/jars/postgresql-42.5.4.jar\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Which Database server are we connecting to?\n",
    "# if running in local Docker, we put both Spark and Postgres servers in the same Docker network ('spark_backend')\n",
    "# Actually, if the postgres server is used ONLY by the Spark server, there is no need to expose its ports\n",
    "hostname=\"db\"  # the service name in docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0a0dec-5637-45af-ae9d-1133e7cf35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = f\"jdbc:postgresql://{hostname}/\"\n",
    "database_name = \"bids_db\"\n",
    "url = server_name + database_name\n",
    "table_name = \"players\"\n",
    "username = \"postgres\"  # your_dbuser_name_here\n",
    "password = \"postgres\"\n",
    "\n",
    "# We don't even need to add 'option(\"driver\", \"org.postgresql.Driver\")'\n",
    "\n",
    "jdbcDF = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"dbtable\", table_name)\\\n",
    "    .option(\"user\", username)\\\n",
    "    .option(\"password\", password).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b8c292-042b-4063-8ee3-980f4ed49f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>Rocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Assasin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>50</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>10</td>\n",
       "      <td>racer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age   occupation\n",
       "0    Alice   25       Rocker\n",
       "1      Bob   30      Assasin\n",
       "2  Charlie   50   politician\n",
       "3    David   10        racer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdbcDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a1cd60-3660-45db-bc12-002f87eb6547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Age</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>נעם</td>\n",
       "      <td>59</td>\n",
       "      <td>Witcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helga</td>\n",
       "      <td>140</td>\n",
       "      <td>hag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  Age occupation\n",
       "0    נעם   59    Witcher\n",
       "1  Helga  140        hag"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a few rows\n",
    "from pyspark.sql.types import StructType,StructField, StringType,IntegerType\n",
    "playerSchema = StructType([StructField('name',StringType(),False), \n",
    "                          StructField('Age',IntegerType(),False),\n",
    "                          StructField('occupation',StringType(),False)\n",
    "                          ])\n",
    "newcomers = [('נעם', 59, 'Witcher'), ('Helga', 140, 'hag')]\n",
    "newPlayers=spark.createDataFrame(data=newcomers, schema= playerSchema)\n",
    "newPlayers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682916af-71ab-492b-a61d-020d4553d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    newPlayers.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"url\", url) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", username) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .save()\n",
    "except ValueError as error:\n",
    "    print(\"Connector write failed\", error)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716de700-cd81-439e-9bcb-5c7118b0a42f",
   "metadata": {},
   "source": [
    "And you can check in the *dbclient*:\n",
    "```\n",
    "bids_db=# select * from players;\n",
    "  name   | age | occupation  \n",
    "---------+-----+-------------\n",
    " Alice   |  25 |  Rocker\n",
    " Bob     |  30 |  Assasin\n",
    " Charlie |  50 |  politician\n",
    " David   |  10 |  racer\n",
    " נעם     |  59 | Witcher\n",
    " Helga   | 140 | hag\n",
    "(6 rows)\n",
    "```\n",
    "PS: the Hebrew text is in the wrong place. A bug in the terminal..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134feedd-a6c5-4a60-8b6e-3a85b44872db",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Now that we are done playing, let's stop the DB and remove it -- execute the steps in the postgres dir README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d8d2d-77b3-42f0-9560-99198b96d898",
   "metadata": {},
   "source": [
    "# Reading / Writing to other databses\n",
    "\n",
    "In the lesson on Streaming we read from Kafka source.\n",
    "Simlarly, we can read from other sources such as mongodb using a *connector* supplied by the database vendor\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec58d92-e413-4b8a-9589-5abfee323018",
   "metadata": {},
   "source": [
    "df = spark.read.format(\"mongo\").option(\"uri\",\n",
    "\"mongodb://127.0.0.1/people.contacts\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eec6dd-b78d-4d00-960d-6981f9cdf218",
   "metadata": {},
   "source": [
    "<br>This will write to a default container in the database you connected to before"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebe21a90-16a1-4fc3-991a-aabdb9772e03",
   "metadata": {},
   "source": [
    "people = spark.createDataFrame([(\"Bilbo Baggins\",  50), (\"Gandalf\", 1000)], [\"name\", \"age\"])\n",
    "people.write.format(\"mongo\").mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
